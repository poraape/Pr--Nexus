---
title: Nexus QuantumI2A2
emoji: üßÆ
colorFrom: indigo
colorTo: green
sdk: docker
sdk_version: "0.0.1"
app_file: start.sh
pinned: false
---
# Nexus QuantumI2A2: An√°lise Fiscal com IA

Nexus QuantumI2A2 √© uma plataforma de auditoria fiscal que combina uma SPA React leve com um backend FastAPI orientado a agentes. O processamento de arquivos, regras fiscais, chamadas de IA e gera√ß√£o de relat√≥rios √© realizado exclusivamente no servidor, garantindo conformidade com o blueprint MAS distribu√≠do.

---

## Funcionalidades Principais

- **Pipeline Multiagente no Backend:** Extra√ß√£o, valida√ß√£o, classifica√ß√£o, cross-validation, intelig√™ncia e contabilidade residem em m√≥dulos Python (`backend/agents/*`) orquestrados por `backend/graph.py`.
- **API Gateway FastAPI:** Endpoints `/api/v1/upload`, `/status/{task_id}`, `/report/{task_id}`, `/chat`, `/llm/generate-json` centralizam autentica√ß√£o, filas e entrega de resultados (`backend/api/endpoints.py`).
- **Ass√≠ncrono e Extens√≠vel:** Tarefas publicadas em RabbitMQ (modo produ√ß√£o) ou executadas inline via thread pool (modo desenvolvimento). O worker dedicado √© inicializado por `python -m backend.worker_main`.
- **Persist√™ncia Completa:** SQLite (padr√£o) ou PostgreSQL gerenciado armazena tasks, status e relat√≥rios (`backend/database/models.py`); ChromaDB mant√©m embeddings para RAG (`backend/agents/consultant_agent.py`).
- **Frontend Thin Client:** O React apenas sobe arquivos suportados (XML, CSV, JSON, PDF, OCR e ZIP) e acompanha o progresso via polling/SSE (`hooks/useAgentOrchestrator.ts`, `components/FileUpload.tsx`).
- **Chat Consultivo com RAG:** Consultor fiscal responde perguntas com contexto indexado no backend.

---

## Arquitetura Atual (MAS Server-Side)

```text
Frontend (React) ‚îÄ‚îÄ‚ñ∫ API Gateway (FastAPI) ‚îÄ‚îÄ‚ñ∫ RabbitMQ ‚îÄ‚îÄ‚ñ∫ Worker (AgentGraph) ‚îÄ‚îÄ‚ñ∫ SQLite (padr√£o) / ChromaDB
                                              ‚îÇ
                                              ‚îî‚îÄ‚îÄ Storage de Arquivos em /data
```

- **Frontend (React/Vite)**  
  - Upload restrito a arquivos compreendidos pelo backend (`components/FileUpload.tsx`).  
  - Polling de status (`/api/v1/status/{task_id}`) e busca de relat√≥rio final (`/api/v1/report/{task_id}`).  
  - Chat via SSE (`/api/v1/chat`) sem expor chaves de API.  

- **FastAPI Gateway (`backend/main.py`, `backend/api/endpoints.py`)**
  - Persiste metadados de tarefas no SQLite local por padr√£o (ou em PostgreSQL se configurado).
  - Publica mensagens em RabbitMQ via `RabbitMQPublisher` ou executa inline com `InlineTaskPublisher`.  
  - Posta atualiza√ß√µes em `SQLAlchemyStatusRepository` e salva relat√≥rios em `SQLAlchemyReportRepository`.

- **Workers (`backend/worker.py`, `backend/worker_main.py`)**  
  - Consumidor RabbitMQ implementado em `RabbitMQConsumer` (`backend/services/task_queue.py`).  
  - `AuditWorker` injeta agentes via `AgentGraph`, atualizando status a cada fase (`backend/graph.py`).  
  - Persist√™ncia de arquivos pela `FileStorage` (`backend/services/storage.py`).  

- **Persist√™ncia e RAG**  
  - `backend/database/models.py`: modelos `Task` e `Report`.  
  - `backend/agents/consultant_agent.py`: indexa√ß√£o no ChromaDB e consultas com LLM server-side (Gemini/DeepSeek).  

---

## Execu√ß√£o Local

### 1. Backend

```bash
python -m venv .venv
source .venv/bin/activate           # PowerShell: .\.venv\Scripts\Activate.ps1
pip install -r backend/requirements.txt
```

Defina as vari√°veis de ambiente (arquivo `.env` na raiz ou export direto):

```env
POSTGRES_DSN=sqlite+aiosqlite:///data/nexus.db
STORAGE_PATH=/data/uploads
CHROMA_PERSIST_DIRECTORY=/data/chroma
SPACE_RUNTIME_DIR=/data                     # raiz √∫nica para dados persistentes
TASK_DISPATCH_MODE=inline              # use "rabbitmq" para produ√ß√£o
RABBITMQ_URL=amqp://guest:guest@localhost:5672/
RABBITMQ_QUEUE=audit_tasks
GEMINI_API_KEY=***
FRONTEND_ORIGIN=http://localhost:5173
```

Com `SPACE_RUNTIME_DIR=/data` definido (padr√£o no `docker-compose.yml`), uploads e embeddings s√£o criados em subpastas de `/data`, permitindo que um √∫nico volume nomeado sobreviva a reinicializa√ß√µes.

Inicie a API:

```bash
uvicorn backend.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Worker de Processamento

- **Modo inline (padr√£o):** nenhuma a√ß√£o extra necess√°ria; as tarefas s√£o executadas em threads dentro do processo FastAPI.
- **Modo RabbitMQ:** defina `TASK_DISPATCH_MODE=rabbitmq`, suba o broker e execute em outro terminal:

```bash
python -m backend.worker_main
```

### 3. Frontend

```bash
npm install
npm run dev -- --host 0.0.0.0 --port 5173
```

A aplica√ß√£o estar√° em `http://localhost:5173`.

---

## Execu√ß√£o com Docker Compose

Um ambiente completo (RabbitMQ, FastAPI, Worker e Vite) est√° definido em `docker-compose.yml`.

```bash
# Exporte a chave do LLM antes de subir, se necess√°rio
export GEMINI_API_KEY=***
docker compose up --build
```

Servi√ßos expostos:

- FastAPI: `http://localhost:8000`
- Frontend: `http://localhost:5173`
- RabbitMQ Management: `http://localhost:15672` (guest/guest)

Volumes nomeados preservam uploads, embeddings e dados do broker (`backend_data`, `rabbitmq_data`).

---

## Estrutura de Pastas Relevante

```
backend/
  agents/                   # Agentes Python (Intelligence, Accountant, etc.)
  api/                      # Endpoints FastAPI
  core/config.py            # Configura√ß√µes e carregamento de env
  database/                 # SQLAlchemy engine e modelos
  graph.py                  # Orquestra√ß√£o do pipeline multiagente
  worker.py                 # AuditWorker e interface MessageBroker
  worker_main.py            # Entry point para consumidor RabbitMQ
  services/
    task_queue.py           # Inline/RabbitMQ publishers + RabbitMQConsumer
    storage.py              # Persist√™ncia de arquivos
frontend (raiz do projeto)
  components/               # UI, upload, dashboards
  hooks/useAgentOrchestrator.ts
  services/                 # httpClient/chatService delegando ao backend
  types.ts                  # Tipos compartilhados com o backend
docker-compose.yml          # Orquestra√ß√£o local completa
backend/Dockerfile          # Imagem base para API e worker
```

Os antigos agentes TypeScript client-side foram removidos (agora toda a l√≥gica est√° em Python).

---

## Vari√°veis de Ambiente Importantes

> **Obrigat√≥rio vs. opcional** ‚Äì As vari√°veis marcadas como "Sim" precisam estar definidas em produ√ß√£o. Quando houver alternativas,
> configure pelo menos uma das op√ß√µes indicadas.

| Vari√°vel | Obrigat√≥ria? | Descri√ß√£o |
| --- | --- | --- |
| `POSTGRES_DSN` | Sim | DSN usado pelo SQLAlchemy para persistir tarefas e relat√≥rios. |
| `STORAGE_PATH` | Sim | Diret√≥rio para uploads persistidos antes do processamento. |
| `CHROMA_PERSIST_DIRECTORY` | Sim | Pasta usada pelo ChromaDB para embeddings. |
| `TASK_DISPATCH_MODE` | Sim | Define o modo de execu√ß√£o das tarefas. O padr√£o √© `inline`, adequado para produ√ß√£o quando RabbitMQ n√£o est√° dispon√≠vel. |
| `RABBITMQ_URL` / `RABBITMQ_QUEUE` | Condicional | Necess√°rias apenas quando `TASK_DISPATCH_MODE=rabbitmq`. |
| `LLM_PROVIDER` | Sim | Escolha do provedor (`gemini`, `deepseek` ou `hybrid`). |
| `GEMINI_API_KEY` | Condicional | Obrigat√≥ria quando `LLM_PROVIDER=gemini` ou `hybrid`. |
| `DEEPSEEK_API_KEY` | Condicional | Obrigat√≥ria quando `LLM_PROVIDER=deepseek` ou `hybrid`. |
| `FRONTEND_ORIGIN` | Sim | Origin autorizado para CORS. |
| `VITE_BACKEND_URL` (frontend) | Opcional | URL do gateway FastAPI consumida pelo SPA. Use `self` (padrao) para reaproveitar host/porta do SPA. |

---

## Testes

O backend possui testes PyTest para agentes e grafo (`backend/tests/*`). Execute:

```bash
pytest backend/tests
```

> Nota: os testes definem `DISABLE_CONSULTANT_AGENT=1` para evitar chamadas externas ao inicializar o consultor de IA.

---

## Observabilidade e disponibilidade

- **Endpoint de sa√∫de:** `GET /health` responde `{ "status": "ok" }` a partir do `backend/main.py`, permitindo que load balancers e monitores verifiquem se a API est√° ativa.
- **Script keep-alive opcional:** para evitar que a Space hiberne, execute periodicamente o utilit√°rio `scripts/keep_alive.py`, que realiza pings no endpoint de sa√∫de.

```bash
python scripts/keep_alive.py --url https://<sua-space>.hf.space --interval 600
```

Vari√°veis de ambiente (`SPACE_URL`, `SPACE_HEALTH_ENDPOINT`, `SPACE_PING_INTERVAL`, `SPACE_PING_TIMEOUT`) tamb√©m podem ser usadas para configurar o script em servi√ßos externos de cron.

---

## CI/CD e deploy para Hugging Face Space

Um workflow GitHub Actions (`.github/workflows/deploy.yml`) automatiza testes, build e deploy:

1. **Lint opcional:** roda `ruff` e `mypy` (n√£o bloqueia o pipeline, apenas antecipa falhas).
2. **Testes e build:** instala depend√™ncias Python, executa `pytest backend/tests`, instala depend√™ncias do frontend (`npm ci`) e roda `npm run build`.
3. **Deploy:** em pushes para `main`, usa a action `huggingface/space-pusher` para enviar o reposit√≥rio para a Space configurada.

### Configura√ß√£o necess√°ria

### Provisionamento da Space (modo gratuito)

- Crie a Space no Hugging Face como `Docker` e selecione o hardware gratuito `CPU Basic`; o arquivo `space.yaml` ja define `app_port=7860` para a execucao direta do container.
- Em *Settings -> Variables & secrets* cadastre `GEMINI_API_KEY` (usa o modelo gratuito `gemini-2.5-flash`) e, se quiser fixar explicitamente, adicione `LLM_PROVIDER=gemini` e `GEMINI_MODEL=gemini-2.5-flash`.
- Nao e preciso banco externo: SQLite, Chroma e uploads persistem em `/data`; use *Factory reset* na Space para limpar o estado quando desejar.
- O script `start.sh` prepara diretorios, aplica Alembic, configura o runtime `PORT` e sobe o `uvicorn` com `--proxy-headers`, garantindo compatibilidade com o proxy da plataforma.
- O primeiro build consome ~10 minutos porque instala OCR (`tesseract` + `poppler`); releases seguintes aproveitam o cache Docker mantido pela Hugging Face.

Crie os seguintes segredos no repositorio GitHub:

| Segredo | Descricao |
| --- | --- |
| `HF_TOKEN` | Token da conta no Hugging Face com permissao de escrita na Space. |
| `HF_SPACE_ID` | Identificador completo da Space (`usuario/nome-da-space`). |

### Fluxo de atualiza√ß√£o

1. Fa√ßa commits das altera√ß√µes.
2. Envie para o branch principal: `git push origin main`.
3. Aguarde o workflow concluir (`CI and Deploy to Space`). Ao final, a Space √© atualizada automaticamente.

Para builds manuais (ex.: hotfix), abra a aba *Actions* no GitHub e dispare `CI and Deploy to Space` via `Run workflow`.

### Rollback

- Identifique o commit saud√°vel (`git log`).
- Recrie o estado desejado (`git revert <sha>` ou `git checkout <sha> && git push origin HEAD:main`).
- O push aciona novamente o workflow, publicando a vers√£o anterior na Space.

Se a Space precisar ser reimplantada sem altera√ß√µes de c√≥digo, execute o workflow manualmente ou utilize `huggingface-cli repo push` com o commit conhecido.

---

## Migra√ß√£o futura para PostgreSQL gerenciado

Para escalar al√©m do SQLite embarcado, siga os passos abaixo para usar um banco PostgreSQL gerenciado (Neon, RDS, Cloud SQL, etc.):

1. **Provisionar o banco:** crie uma inst√¢ncia PostgreSQL e obtenha a URL completa (incluindo usu√°rio, senha, host, porta e banco).
2. **Atualizar vari√°veis de ambiente:** defina `POSTGRES_DSN` com o DSN do provedor e remova `SPACE_RUNTIME_DIR`, `STORAGE_PATH` e `CHROMA_PERSIST_DIRECTORY` se for usar armazenamento externo diferente do `/data`.
3. **Executar migra√ß√µes:** rode `alembic upgrade head` ou reinicie o backend; o `backend/main.py` aplica as migra√ß√µes automaticamente na inicializa√ß√£o.
4. **Ajustar Docker Compose (opcional):** adicione um servi√ßo externo ou utilize vari√°veis apontando para o endpoint gerenciado. Remova o volume `backend_data` se os uploads e embeddings tamb√©m forem migrados para outro storage.
5. **Verificar permiss√µes:** garanta que o usu√°rio tenha privil√©gios de cria√ß√£o de tabelas e √≠ndices necess√°rios para `Base.metadata.create_all` e migra√ß√µes Alembic.

---

## Seguran√ßa

- Chaves de LLM s√£o carregadas apenas no backend via vari√°veis de ambiente (`backend/core/config.py`).
- Frontend n√£o cont√©m segredos; interage exclusivamente com a API.
- Upload de arquivos agora √© validado no cliente para aceitar somente formatos processados pelo backend (`components/FileUpload.tsx`).  
- Recomenda-se habilitar HTTPS, secret management e autentica√ß√£o no deployment final.

